[[Paper]]() [[–•–∞–±—Ä]]() [[Model Card]](https://huggingface.co/sberbank-ai/RuDOLPH-350M) [[Colab]](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing) [[Kaggle]]()

Fine-Tuning example by [@Alex Wortega](https://github.com/AlexWortega) 
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12YRRzhl5cHER_U2F-buQxif8GlhMPWq3?usp=sharing)

## <img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/rudolph.png?token=GHSAT0AAAAAABQH6MST7ZEGAF274DV33K7KYOYRSBQ" height="60"/> RuDOLPH ü¶åüéÑ‚òÉÔ∏è

*One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP*

---

**Ru**ssian **D**iffusion **O**n **L**anguage **P**icture **H**yper-modality (RuDOLPH) is a fast 
and light text-image-text transformer (350M GPT-3) designed for a quick and easy fine-tuning setup 
for the solution of various tasks: from generating images by text description and image classification 
to visual question answering and more. This model demonstrates the power of Hyper-modality Transformers.

*(!!!) Hyper-modality means generalized multi-modal, e.g., model that consists of two multi-modal parts: text-2-image and image-2-text becomes text and image hyper-modality model*


![](./pics/scheme.png)

# Sparse Attention Mask
`row - col - row - [last] conv`

![](./pics/attention_masks.png)

# Models
+ [350M (RuDOLPH)](https://huggingface.co/sberbank-ai/RuDOLPH-350M)
+ 1.3B (In Progress)
+ 4B (In Progress)


![](./pics/high_res.png)

# Installing
```
pip install rudolph==0.0.1rc1
```

# Usage
### Init models
```python
from rudalle import get_tokenizer, get_vae
from rudalle.utils import seed_everything
from rudalle.image_prompts import ImagePrompts

from rudolph.model import get_rudolph_model
from rudolph.pipelines import zs_clf, generate_codebooks, self_reranking_by_image, self_reranking_by_text, show, generate_captions, generate_texts
from rudolph import utils

device = 'cuda'
model = get_rudolph_model('350M', fp16=True, device=device)
model.to(device);
tokenizer = get_tokenizer()
vae = get_vae(dwt=False).to(device)
```
### Text Generation
```python
generate_texts(
    tokenizer,
    model,
    template='–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ ',
    top_k=32, top_p=0.6, texts_num=32, bs=32, seed=42
)[:8]

[{'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –ª–µ—Å–æ–º –∏ —Ä–µ–∫–æ–π. –≤–∏–¥ —Å –≤–æ–∑–¥—É—Ö–∞ –Ω–∞ —Å–µ–ª—å—Å–∫—É—é –º–µ—Å—Ç–Ω–æ—Å—Ç—å. –ø–µ–π–∑–∞–∂ —Å –ª–µ—Å–æ–º –∏ —Ä–µ–∫–æ–π. –≤–∏–¥ –Ω–∞ –≥–æ—Ä—ã —Å –±–µ—Å–ø–∏–ª–æ—Ç–Ω–∏–∫–∞', 'ppl': 82.94},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ –≤ —Å—Ç–∏–ª–µ —Ä–µ–∞–ª–∏–∑–º, –∞–≤—Ç–æ—Ä –∫–æ—Ç–æ—Ä–æ–π —Å–µ—Ä–≥–µ–π –≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á –¥–æ—Ä–æ—Ñ–µ–µ–≤', 'ppl': 112.73},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å —Ä–µ–∫–æ–π –∏ –æ–∑–µ—Ä–æ–º - –æ–±–æ–∏ –¥–ª—è —Ä–∞–±–æ—á–µ–≥–æ —Å—Ç–æ–ª–∞, –∫–∞—Ä—Ç–∏–Ω–∫–∏, —Ñ–æ—Ç–æ', 'ppl': 125.55},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å —Ä–µ–∫–æ–π –∏ –º–æ—Å—Ç–æ–º —á–µ—Ä–µ–∑ —Ä–µ–∫—É –≤ —Å—É–º–µ—Ä–∫–∞—Ö', 'ppl': 170.83},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –≥–æ—Ä–∞–º–∏ –≤ —Ç—É–º–∞–Ω–µ - –≥–æ—Ä—ã –≤ —Ç—É–º–∞–Ω–µ', 'ppl': 180.72},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –ª–µ—Å–æ–º –∏ –ª—É–≥–æ–º –≤ —Å—É–º–µ—Ä–∫–∞—Ö', 'ppl': 185.84},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –æ–∑–µ—Ä–æ–º –∏ –ª–µ—Å–æ–º –Ω–∞ –∑–∞–¥–Ω–µ–º –ø–ª–∞–Ω–µ', 'ppl': 199.84},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –≤–∏–¥–æ–º –Ω–∞ –≥–æ—Ä—ã –≤ —Ç–∞–∏–ª–∞–Ω–¥–µ', 'ppl': 219.86}]
```

### Setup for Fast Image Generation

```python
text = '—Ä–∏—Å—É–Ω–æ–∫ –∫–æ—Ç–∞'
bs, images_num = 48, 48
top_k, top_p = 512, 0.9
with torch.no_grad():
    codebooks = generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=bs)
    ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=bs)
    images = vae.decode(codebooks[ppl_text.argsort()[:4]])
images = torchvision.utils.make_grid(images, nrow=2)
img = torchvision.transforms.functional.to_pil_image(images)
img
```
![](./pics/pipelines/cat_drawing.png)

### Image Generation + Self Reranking
```python
text = '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –æ–∑–µ—Ä–æ–º –∏ –ª–µ—Å–æ–º –Ω–∞ –∑–∞–¥–Ω–µ–º –ø–ª–∞–Ω–µ'
images_num = 256
seed_everything(42)
codebooks = []
for top_k, top_p, images_num in [
    (2048, 0.99, images_num),
    (1024, 0.99, images_num),
    (1024, 0.98, images_num),
]:
    codebooks.append(generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=32))

codebooks = torch.cat(codebooks)

ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=32)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake.png)


```python
text = '–∑–∏–º–Ω–µ–µ –≤—Ä–µ–º—è –≥–æ–¥–∞'

ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=32)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake_winter.png)


```python
text = '–Ω–æ—á–Ω–æ–µ –≤—Ä–µ–º—è —Å—É—Ç–æ–∫'

ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=32)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake_night.png)


### Image Prompt (like Inpainting)
![](pics/pipelines/lake_image_prompt.png)
```python
text = '–ª–æ–¥–∫–∞ —Å –∞–ª—ã–º–∏ –ø–∞—Ä—É—Å–∞–º–∏'

images_num = 1024
bs = 32

borders = {'up': 6, 'left': 4, 'right': 6, 'down': 2}
image_prompts = ImagePrompts(pil_img, borders, vae, device, crop_first=True)

seed_everything(42)
codebooks = []
for top_k, top_p, images_num in [
    (1024, 0.99, images_num),
]:
    codebooks.append(
        generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=bs, image_prompts=image_prompts)
    )

codebooks = torch.cat(codebooks)

ppl_text, ppl_image = self_reranking_by_text(
    text,
    codebooks,
    tokenizer,
    model,
    bs=bs,
)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake_ship.png)

### Diffusion (TODO, see [Colab](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing))

### Image Captioning + Self Reranking

```python
texts = generate_captions(pil_img, tokenizer, model, vae, template='–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ ', top_k=8, captions_num=128, bs=32, top_p=0.6, seed=42)
ppl_text, ppl_image = self_reranking_by_image(texts, pil_img, tokenizer, model, vae, bs=32, seed=42)
for idx in ppl_image.argsort()[:8]:
    print(f'-{texts[idx]}')
```

![](./pics/pipelines/final_lake_ship.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —è —Ö–æ—á—É —É–≤–∏–¥–µ—Ç—å –∫–∞–∫ –≤—ã–≥–ª—è–¥–∏—Ç –¥–æ–º –≤ –≥–æ—Ä–∞—Ö
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–∞ –ª–æ–¥–∫–∞ —Å –∫–∞—è–∫–æ–º –∏ –ª–µ—Å–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω –¥–æ–º —Å –±–∞—Å—Å–µ–π–Ω–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ ‚Äì –ø–µ–π–∑–∞–∂ ‚Äì –≥–æ—Ä—ã ‚Äì –æ–¥–Ω–∞ –∏–∑ —Å–∞–º—ã—Ö –∫—Ä–∞—Å–∏–≤—ã—Ö –º–µ—Å—Ç –Ω–∞ –ø–ª–∞–Ω–µ—Ç–µ
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ: –≤ –Ω–æ—Ä–≤–µ–≥–∏–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –≤ –≥–æ—Ä–∞—Ö
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —è —Ö–æ—á—É –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å –¥–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –¥–æ–º–∏–∫ –Ω–∞ –≥–æ—Ä–µ
```

![](./pics/pipelines/captioning_dog.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω —Ä—ã–∂–∏–π –ø–µ—Å. –Ω–∞ —Ñ–æ—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω —Ä—ã–∂–∏–π –ø–µ—Å
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –¥–ª–∏–Ω–Ω—ã–º –Ω–æ—Å–æ–º –∏ –¥–ª–∏–Ω–Ω—ã–º –Ω–æ—Å–æ–º –∏ –∫–æ—Ä–æ—Ç–∫–æ–π —à–µ—Ä—Å—Ç—å—é
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –¥–ª–∏–Ω–Ω—ã–º–∏ —É—à–∞–º–∏ –∏ –∫–æ—Ä–æ—Ç–∫–æ–π —à–µ—Ä—Å—Ç—å—é
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ —Å–æ–±–∞–∫–∞ —Å –±–æ–ª—å—à–∏–º–∏ –≥–ª–∞–∑–∞–º–∏ –∏ –¥–ª–∏–Ω–Ω—ã–º –Ω–æ—Å–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –±–µ–ª—ã–π –º–µ–¥–≤–µ–¥—å
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ –ø–æ—Ö–æ–∂–∞ –Ω–∞ —Å—Ç–∞—Ñ—Ñ–æ—Ä–¥–∞ –∏ –±—É–ª—å—Ç–µ—Ä—å–µ—Ä–∞. —Ñ–æ—Ç–æ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ –ø–æ—Ö–æ–∂–∞ –Ω–∞ –±–∏–≥–ª—è –∏ –Ω–∞ —Å–æ–±–∞–∫—É
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –¥–ª–∏–Ω–Ω—ã–º–∏ —É—à–∞–º–∏ –∏ –¥–ª–∏–Ω–Ω—ã–º–∏ —É—à–∞–º–∏ –∏
```

![](./pics/pipelines/captioning_street.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ —É–ª–∏—Ü–∞ —Å —Å–≤–µ—Ç–æ—Ñ–æ—Ä–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –¥–æ–º –Ω–∞ —É—á–∞—Å—Ç–∫–µ –∏–∂—Å
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ –¥–æ—Ä–æ–≥–∞ —Å –¥–≤—É–º—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è–º–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –≤–∏–¥ —Å –≤–æ–∑–¥—É—Ö–∞ –Ω–∞ –∂–∏–ª–æ–π —Ä–∞–π–æ–Ω, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ —É–ª–∏—Ü–µ –∏ –≤ —Ä–∞–π–æ–Ω–µ –∂–∏–ª–æ–≥–æ –∫–æ–º–ø–ª–µ–∫—Å–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –≤–∏–¥ –Ω–∞ –∑–¥–∞–Ω–∏–µ —Å –æ–∫–Ω–∞–º–∏ –∏ –æ–∫–Ω–∞–º–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ –¥–æ—Ä–æ–≥–∞ —Å —Å–≤–µ—Ç–æ—Ñ–æ—Ä–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –¥–æ–º –Ω–∞–ø—Ä–æ—Ç–∏–≤ —Å—Ç–∞–Ω—Ü–∏–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –∂–∏–ª–æ–π –¥–æ–º
```

![](./pics/pipelines/captioning_moto.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –º–æ—Ç–æ—Ü–∏–∫–ª –∏–∂ —é–ø–∏—Ç–µ—Ä
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ –º–æ–ª–æ–¥–∞—è –∂–µ–Ω—â–∏–Ω–∞ —Å –∫–∞—Ä–µ –Ω–∞ —Ñ–æ–Ω–µ –¥–µ—Ä–µ–≤—è–Ω–Ω–æ–≥–æ –¥–æ–º–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂—ë–Ω –º–æ—Ç–æ—Ü–∏–∫–ª
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –≤–µ–ª–æ–≥–æ–Ω—â–∏–∫
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ –º–æ—Ç–æ–∫—É–ª—å—Ç–∏–≤–∞—Ç–æ—Ä
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –∑–¥–∞–Ω–∏–µ
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ –¥–µ–≤—É—à–∫–∞ —Å –≤–µ–ª–æ—Å–∏–ø–µ–¥–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –º–æ–ø–µ–¥
```

### Zero-Shot Image Classification using PPL
```python
import base64
import requests
from PIL import Image
from io import BytesIO

bs4_urls = requests.get('https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/pipelines/cats_vs_dogs_bs4.json').json()

f, ax = plt.subplots(2,4, figsize=(12,6))

for i, bs4_url in enumerate(bs4_urls):
    pil_img = Image.open(BytesIO(base64.b64decode(bs4_url)))
    
    classes = ['–∫–æ—à–∫–∞', '—Å–æ–±–∞–∫–∞']
    preds = zs_clf(
        pil_img, 
        classes,
        model, 
        tokenizer,
        vae,
        template = '–Ω–∞ —Ñ–æ—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞', 
    )
    ax[i//4, i%4].imshow(pil_img)
    ax[i//4, i%4].set_title(preds['class'])
```
![](./pics/pipelines/zs_clf.png)

### Linear Probe (TODO, see [Colab](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing))

# Authors: 

+ Alex Shonenkov: [Github](https://github.com/shonenkov), [Kaggle GM](https://www.kaggle.com/shonenkov)
+ Michael Konstantinov: [Mishin Learning](https://t.me/mishin_learning), [Transformer Community](https://transformer.community/)

<img src='https://habrastorage.org/webt/2w/5k/2r/2w5k2reyf6yqa4s7ywmmioaaieg.png' alt="Drawing" width="200" />  <img src='https://habrastorage.org/webt/eq/ft/g3/eqftg3_8l1b_fpimhiof7knytzk.png' alt="Drawing" width="200" />

# Citation

```
@article{shonenkov2022ruDolph,
  title         = {RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP},
  author        = {Alex Shonenkov and Michael Konstantinov},
  year          = {2022},
  eprint        = {...},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL}
}
```

```
@misc{github2022ruDolph,
  title         = {RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP},
  author        = {Alex Shonenkov and Michael Konstantinov},
  year          = {2022},
  howpublished  = {\url{https://github.com/sberbank-ai/ru-dolph}},
}
```

# Supported by

[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sberai-logo.png" height="115"/>](https://github.com/sberbank-ai) \
[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sberdevices-logo.png" height="40"/>](https://sberdevices.ru)

[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sbercloud-logo.png" height="80"/>](https://sbercloud.ru/) \
[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/airi-logo.png" height="50"/>](https://airi.net)
