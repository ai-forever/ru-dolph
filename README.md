[[Paper]]() [[–•–∞–±—Ä]]() [[Model Card]](https://huggingface.co/sberbank-ai/RuDOLPH-350M) [[Colab]](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing) [[Kaggle]]()


## <img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/rudolph.png?token=GHSAT0AAAAAABQH6MST7ZEGAF274DV33K7KYOYRSBQ" height="60"/> RuDOLPH ü¶åüéÑ‚òÉÔ∏è

*One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP*

---

**Ru**ssian **D**iffusion **O**n **L**anguage **P**icture **H**yper-modality (RuDOLPH) is a fast 
and light text-image-text transformer (350M GPT-3) designed for a quick and easy fine-tuning setup 
for the solution of various tasks: from generating images by text description and image classification 
to visual question answering and more. This model demonstrates the power of Hyper-modality Transformers.

*(!!!) Hyper-modality means generalized multi-modal, e.g., model that consists of two multi-modal parts: text-2-image and image-2-text becomes text and image hyper-modality model*


![](./pics/scheme.png)

# Sparse Attention Mask
`row - col - row - [last] conv`

![](./pics/attention_masks.png)

# Models
+ [350M (RuDOLPH)](https://huggingface.co/sberbank-ai/RuDOLPH-350M)
+ 1.3B (In Progress)
+ 4B (In Progress)


![](./pics/high_res.png)

# Installing
```
pip install rudolph==0.0.1rc8
```

# Usage

Fine-Tuning example by [@Alex Wortega](https://github.com/AlexWortega) 
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12YRRzhl5cHER_U2F-buQxif8GlhMPWq3?usp=sharing)

### Init models
```python
from rudalle import get_tokenizer, get_vae
from rudalle.utils import seed_everything
from rudalle.image_prompts import ImagePrompts

from rudolph.model import get_rudolph_model
from rudolph.pipelines import zs_clf, generate_codebooks, self_reranking_by_image, self_reranking_by_text, show, generate_captions, generate_texts
from rudolph import utils

device = 'cuda'
model = get_rudolph_model('350M', fp16=True, device=device)
model.to(device);
tokenizer = get_tokenizer()
vae = get_vae(dwt=False).to(device)
```

### Setup for Fast Image Generation

```python
text = '—Å—Ç–∞—Ä–∏–Ω–Ω—ã–π –±—É–¥–∏–ª—å–Ω–∏–∫ –º–Ω–æ–≥–æ—É–≥–æ–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã'
bs, images_num = 48, 48
top_k, top_p = 512, 0.9
with torch.no_grad():
    codebooks = generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=bs)
    ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=bs)
    images = vae.decode(codebooks[ppl_text.argsort()[:4]])
images = torchvision.utils.make_grid(images, nrow=2)
img = torchvision.transforms.functional.to_pil_image(images)
img
```
![](./pics/pipelines/example.png)


### Text Generation
```python
generate_texts(
    tokenizer,
    model,
    template='–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ ',
    top_k=32, top_p=0.8, texts_num=32, bs=32, seed=42
)[:8]

[{'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ –∏ –¥–µ—Ä–µ–≤—å—è –≤ –≥–æ—Ä–∞—Ö —Å —Å–∏–Ω–∏–º –Ω–µ–±–æ–º –∏ –æ–±–ª–∞–∫–∞–º–∏ –≤ —Å–æ–ª–Ω–µ—á–Ω—ã–π –¥–µ–Ω—å. –∫–∞—Ä–ø–∞—Ç—ã —É–∫—Ä–∞–∏–Ω–∞', 'ppl': 155.72},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –≥–æ—Ä–Ω—ã–º –æ–∑–µ—Ä–æ–º –∏ –∫—Ä–∞—Å–∏–≤—ã–º –ø–µ–π–∑–∞–∂–µ–º –Ω–∞ –≤–æ—Å—Ö–æ–¥–µ —Å–æ–ª–Ω—Ü–∞', 'ppl': 195.81},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –≥–æ—Ä–Ω—ã–º–∏ –≤–µ—Ä—à–∏–Ω–∞–º–∏ –∏ —á–∏—Å—Ç—ã–º –Ω–µ–±–æ–º', 'ppl': 219.57},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –≥–æ—Ä–∞–º–∏ –≤ —Ç—É–º–∞–Ω–µ, –ø–æ–∫—Ä—ã–≤–∞—é—â–∏–º–∏ –≥–æ—Ä—ã', 'ppl': 221.36},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ –∏ –≤–æ–¥–æ–ø–∞–¥ –≤ –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º –ø–∞—Ä–∫–µ –ø—Ö—É—Ç—Ç–∞ –≤ —Ç–∞–∏–ª–∞–Ω–¥–µ', 'ppl': 248.82},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –≥–æ–ª—É–±—ã–º –Ω–µ–±–æ–º –∏ –±–µ–ª—ã–º –æ–±–ª–∞–∫–æ–º', 'ppl': 260.76},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å —Ä–µ–∫–æ–π, –≥–æ—Ä—ã –∏ –≥–æ–ª—É–±–æ–µ –Ω–µ–±–æ', 'ppl': 273.1},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –∑–µ–ª–µ–Ω—ã–º–∏ –¥–µ—Ä–µ–≤—å—è–º–∏ –∏ –≥–æ–ª—É–±—ã–º –Ω–µ–±–æ–º', 'ppl': 286.22}]
```

### Image Generation + Self Reranking
```python
text = '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –æ–∑–µ—Ä–æ–º –∏ –ª–µ—Å–æ–º –Ω–∞ –∑–∞–¥–Ω–µ–º –ø–ª–∞–Ω–µ'
images_num, bs = 256, 32
seed_everything(42)
codebooks = []
for top_k, top_p, images_num in [
    (2048, 0.975, images_num),
    (1536, 0.975, images_num),
    (1024, 0.975, images_num),
]:
    codebooks.append(generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=bs))

codebooks = torch.cat(codebooks)

ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=bs)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake.png)


```python
text = '–∑–∏–º–Ω–µ–µ –≤—Ä–µ–º—è –≥–æ–¥–∞'

ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=32)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake_winter.png)


```python
text = '–Ω–æ—á–Ω–æ–µ –≤—Ä–µ–º—è —Å—É—Ç–æ–∫'

ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=32)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake_night.png)


### Image Prompt (like Inpainting)
![](pics/pipelines/lake_image_prompt.png)
```python
text = '–ª–æ–¥–∫–∞ —Å –∞–ª—ã–º–∏ –ø–∞—Ä—É—Å–∞–º–∏'

images_num = 1024
bs = 32

borders = {'up': 6, 'left': 4, 'right': 6, 'down': 2}
image_prompts = ImagePrompts(pil_img, borders, vae, device, crop_first=True)

seed_everything(42)
codebooks = []
for top_k, top_p, images_num in [
    (1024, 0.99, images_num),
]:
    codebooks.append(
        generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=bs, image_prompts=image_prompts)
    )

codebooks = torch.cat(codebooks)

ppl_text, ppl_image = self_reranking_by_text(
    text,
    codebooks,
    tokenizer,
    model,
    bs=bs,
)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake_ship.png)

### Diffusion (TODO, see [Colab](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing))

### Image Captioning + Self Reranking

```python
texts = generate_captions(pil_img, tokenizer, model, vae, template='–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ ', top_k=16, captions_num=128, bs=32, top_p=0.6, temperature=0.8, seed=43, limit_eos=False)
ppl_text, ppl_image = self_reranking_by_image(texts, pil_img, tokenizer, model, vae, bs=32, seed=42)
for idx in ppl_image.argsort()[:8]:
    print(f'-{texts[idx]}')
```

![](./pics/pipelines/final_lake_ship.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ - –∫–∞—è–∫ —Å –ø–ª–∞–≤–∞—é—â–µ–π –Ω–∞ –Ω–µ–º –∂–µ–Ω—â–∏–Ω–æ–π
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ - –ª–æ–¥–∫–∞ —Å –ø—Ä–∏–∑—Ä–∞–∫–∞–º–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∫–æ—Ä–∞–±–ª—å ¬´ ¬ª, –≤–∏–¥ —Å –≤–æ–∑–¥—É—Ö–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –ª–æ–¥–∫–∞ —Å –ø–∞—Ä—É—Å–æ–º –∏ 3d —ç—Ñ—Ñ–µ–∫—Ç–æ–º, –≤–∏–¥ —Å –≤–æ–∑–¥—É—Ö–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –ª–æ–¥–∫–∞ —Å –ø—Ä–∏–≤–∏–¥–µ–Ω–∏—è–º–∏, –≤–∏–¥ —Å–≤–µ—Ä—Ö—É
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –ø–æ–¥–≤–æ–¥–Ω–∞—è –ª–æ–¥–∫–∞ ¬´–∞–∫—É–ª–∞¬ª, –≤–∏–¥ —Å –≤–æ–∑–¥—É—Ö–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ - –Ω–∞–¥—É–≤–Ω–∞—è –ª–æ–¥–∫–∞ —Å –∂–µ—Å—Ç–∫–∏–º –¥–Ω–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å —Å–∞–π—Ç–∞ esquire, –∏–∑–æ–±—Ä–∞–∂–µ–Ω –º–∞–ª–µ–Ω—å–∫–∏–π –∫—Ä–∞—Å–Ω—ã–π –∫–æ—Ä–∞–±–ª—å
```

![](./pics/pipelines/captioning_dog.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –¥–ª–∏–Ω–Ω—ã–º–∏ —É—à–∞–º–∏, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –±–æ–ª—å—à–∏–º–∏ —É—à–∞–º–∏ –∏ —Å –¥–ª–∏–Ω–Ω—ã–º–∏ –ª–∞–ø–∞–º–∏, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –±–æ–ª—å—à–∏–º–∏ —É—à–∞–º–∏ –∏ –º–æ—Ä–¥–æ–π —Å–æ–±–∞–∫–∏, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –±–µ–ª–æ–π –≥—Ä–∏–≤–æ–π, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏ —Å–æ–±–∞–∫–∞ —Å –∫–æ—Ä–∏—á–Ω–µ–≤—ã–º —Ü–≤–µ—Ç–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –±–æ–ª—å—à–∏–º–∏ —É—à–∞–º–∏ –∏ —Å–æ–±–∞–∫–∞ —Å –±–æ–ª—å—à–∏–º–∏ —É—à–∞–º–∏, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –±–æ–ª—å—à–∏–º–∏ —É—à–∞–º–∏ –∏ –∫–æ—Ä–∏—á–Ω–µ–≤—ã–º –º–µ—Ö–æ–º, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –±–µ–ª–æ–π –≥—Ä–∏–≤–æ–π, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏ —Å–æ–±–∞–∫–∞ —Å –±–µ–ª–æ–π –≥—Ä–∏–≤–æ–π
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –±–æ–ª—å—à–∏–º–∏ —É—à–∞–º–∏ –∏ –¥–ª–∏–Ω–Ω—ã–º–∏ —É—à–∞–º–∏, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏
```

![](./pics/pipelines/captioning_street.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å ¬´–∞—Ä–±–∞—Ç¬ª
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –≤–∏–¥–Ω–æ –∑–¥–∞–Ω–∏–µ —Å –æ–∫–Ω–∞–º–∏ –≤ —Ü–µ–Ω—Ç—Ä–µ –≥–æ—Ä–æ–¥–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –∂–∏–ª–æ–π –¥–æ–º —Å –≤–∏–¥–æ–º –Ω–∞ —É–ª–∏—Ü—É
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –≤–∏–¥–Ω–µ–µ—Ç—Å—è –∑–¥–∞–Ω–∏–µ –≤ —Ü–µ–Ω—Ç—Ä–µ –≥–æ—Ä–æ–¥–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –≤–∏–¥ –Ω–∞ –∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å, –≤–∏–¥ —Å —É–ª–∏—Ü—ã
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –≤–∏–¥–Ω–∞ –±–∞—à–Ω—è –±–∞–Ω–∫–∞ —Å–±–µ—Ä–±–∞–Ω–∫–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω —Ñ–∞—Å–∞–¥ –∑–¥–∞–Ω–∏—è —Å –æ–∫–Ω–∞–º–∏ –≤ —Ü–µ–Ω—Ç—Ä–µ –≥–æ—Ä–æ–¥–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –≤–∏–¥–Ω–µ–µ—Ç—Å—è –∑–¥–∞–Ω–∏–µ —Å –±–∞–ª–∫–æ–Ω–æ–º
```

![](./pics/pipelines/captioning_moto.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –º–æ—Ç–æ—Ü–∏–∫–ª –∏–∂ —é–ø–∏—Ç–µ—Ä –≤–∞—Ä–∏–∞–Ω—Ç —Å –º–æ—Ç–æ—Ä–æ–º –æ—Ç –∏–∂ —é–ø–∏—Ç–µ—Ä, –≤–∏–¥ —Å–∑–∞–¥–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –º–æ—Ç–æ—Ü–∏–∫–ª —Å –º–æ—Ç–æ—Ä–æ–º –∏ –º–æ—Ç–æ—Ä–æ–º —Å –º–æ—Ç–æ—Ä–æ–º –æ—Ç –º–æ—Ç–æ—Ü–∏–∫–ª–∞, –≤–∏–¥ —Å–±–æ–∫—É
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –º–æ—Ç–æ—Ü–∏–∫–ª —Å –∫—É–∑–æ–≤–æ–º –∏–∑ —Ñ–∏–ª—å–º–∞ ¬´–±—ç—Ç–º–µ–Ω –ø—Ä–æ—Ç–∏–≤ —Å—É–ø–µ—Ä–º–µ–Ω–∞¬ª, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –≤–µ–ª–æ—Å–∏–ø–µ–¥ —Å –≤–µ–ª–æ—Å–∏–ø–µ–¥–æ–º –≤ –≥–∞—Ä–∞–∂–µ, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –º–æ—Ç–æ—Ü–∏–∫–ª —Å –º–æ—Ç–æ—Ü–∏–∫–ª–æ–º ¬´–º–æ—Ç–æ—Ü–∏–∫–ª¬ª –≤–∏–¥ —Å–∑–∞–¥–∏, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –≤–µ–ª–æ—Å–∏–ø–µ–¥ —Å –∫–æ—Ä–∑–∏–Ω–æ–π –¥–ª—è –ø–æ–∫—É–ø–æ–∫, –≤–∏–¥ —Å–∑–∞–¥–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –≤–µ–ª–æ—Å–∏–ø–µ–¥ —Å –º–æ—Ç–æ—Ä–æ–º –æ—Ç –º–æ—Ç–æ—Ü–∏–∫–ª–∞ –∏–∂ —é–ø–∏—Ç–µ—Ä –≤–∞—Ä–∏–∞–Ω—Ç 2 –≤–∞—Ä–∏–∞–Ω—Ç–∞, –≤–∏–¥ —Å–±–æ–∫—É
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –º–æ—Ç–æ—Ü–∏–∫–ª —Å –º–æ—Ç–æ—Ü–∏–∫–ª–æ–º ¬´ ¬ª, –≤–∏–¥ —Å–ø–µ—Ä–µ–¥–∏
```

### Zero-Shot Image Classification using PPL
```python
import base64
import requests
from PIL import Image
from io import BytesIO

bs4_urls = requests.get('https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/pipelines/cats_vs_dogs_bs4.json').json()

f, ax = plt.subplots(2,4, figsize=(12,6))

for i, bs4_url in enumerate(bs4_urls):
    pil_img = Image.open(BytesIO(base64.b64decode(bs4_url)))
    
    classes = ['–∫–æ—à–∫–∞', '—Å–æ–±–∞–∫–∞']
    preds = zs_clf(
        pil_img, 
        classes,
        model, 
        tokenizer,
        vae,
        template = '{}', 
    )
    ax[i//4, i%4].imshow(pil_img)
    ax[i//4, i%4].set_title(preds['class'])
```
![](./pics/pipelines/zs_clf.png)

### Linear Probe (TODO, see [Colab](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing))

# Authors: 

+ Alex Shonenkov: [Github](https://github.com/shonenkov), [Kaggle GM](https://www.kaggle.com/shonenkov)
+ Michael Konstantinov: [Mishin Learning](https://t.me/mishin_learning), [Transformer Community](https://transformer.community/)

<img src='https://habrastorage.org/webt/2w/5k/2r/2w5k2reyf6yqa4s7ywmmioaaieg.png' alt="Drawing" width="200" />  <img src='https://habrastorage.org/webt/eq/ft/g3/eqftg3_8l1b_fpimhiof7knytzk.png' alt="Drawing" width="200" />

# Citation

```
@article{shonenkov2022ruDolph,
  title         = {RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP},
  author        = {Alex Shonenkov and Michael Konstantinov},
  year          = {2022},
  eprint        = {...},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL}
}
```

```
@misc{github2022ruDolph,
  title         = {RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP},
  author        = {Alex Shonenkov and Michael Konstantinov},
  year          = {2022},
  howpublished  = {\url{https://github.com/sberbank-ai/ru-dolph}},
}
```

# Supported by

[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sberai-logo.png" height="115"/>](https://github.com/sberbank-ai) \
[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sberdevices-logo.png" height="40"/>](https://sberdevices.ru)

[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sbercloud-logo.png" height="80"/>](https://sbercloud.ru/) \
[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/airi-logo.png" height="50"/>](https://airi.net)
